# Homework 1: Odd-Even Sort

                                                                    113062573 余侞璇

## A. Implementation

### 1. How do you handle an arbitrary number of input items and processe

* 工作量分配
  
    每個 process 處理的工作量為(the size of array n) / (number of process)，並取了ceiling，以免不能整除時，最後一個 process 被分配到太大的工作量。

    ``` int chunk = ceil(arr_size / double(size)); ```

* 資料讀取
  
  每個 process 根據自己的 rank id 和剛才算出的工作量 chunk，得到讀取 input file 的起始點 ( start )。為了平行化，使用 MPI_File_read_at 讓 process 從 start 讀取他被分配到要處理的部分。

* 資料預處理
  
  讀取完的資料會放在 process 的 local array ***data*** 裡面，我採用的方法是先對本地陣列進行一次排序，等到 odd-even sort phase 時，再把 process 視為一個元素單位，使其與鄰近的 process 做數據交換並 merge and sort。

### 2. How do you sort in your program ?

process 的總數為 size，故 for 迴圈最多進行 size 次的 odd-even sort，就能夠排序完成。

每次迴圈會判斷現在的 phase。在 even phase 時，rank 如果是奇數，就會跟右邊的 process 交換本地陣列；rank 如果是偶數，則會跟左邊的 process 交換本地陣列。odd phase 則反之。雙方換完資料後，才做後續的比對以及 sorting 。在每組 process pair中，左邊 process 會希望收集到 sorting 後前半部較小的資料，而右邊則是想要後半部較大的資料。

注意有些 process 持有的 data 可能已經在排序好的位置，故並非每次都有交換整個本地陣列的必要。因此在左右 process 交換數據之前，先呼叫一次 `MPI_Sendrecv`，將左邊 process 本地陣列最大的資料與右邊 process 本地陣列最小的資料交換，如果左邊大於右邊，才需要做後續：

* 再呼叫一次 MPI_Sendrecv 交換兩邊的本地陣列

* 左邊的 process 會從頭比較雙方的陣列，透過 index 移動，不斷將兩者陣列中較小的資料留下，直到收集滿本地陣列的大小
  
* 右邊的 process 會從尾比較雙方的陣列，透過 index 移動，不斷將兩者陣列中較大的資料留下，直到收集滿本地陣列的大小

### 3. Other efforts you’ve made in your program

* Early Stop
  
  如果有 k 個 process，原本的 odd-even sort 會執行 k 次迴圈才結束。但若是 odd-even sort 在 k 次以內就完成了所有排序，剩下的迴圈等於在進行無意義的 communication，不斷交換並檢查那些早就排序好的資料們。因此我新增了 early stop 的部分，在執行超過 20 個迴圈後(此數字根據測試多個 testcase 後設定)，利用 `MPI_Allreduce` 分享自己是否 sorted 的訊息給其他所有的 process。若是在 odd phase 與 even phase 中所有的 process 都是已 sorted，便可提早離開迴圈。

  這個方法雖然在需要執行超過20次迴圈才能結束的 case 中，會多出呼叫 MPI_Allreduce 的 communication 開銷，但經實測，他在20次內就 sorting 好的 case 上能減少的 MPI_Sendrecv 時間更多，故最後仍然採用。

    ```cpp
    odd_sorted = 0;
    even_sorted = 0;
    if (i >= 20)
    {
        if(!phase)
        {
            MPI_Allreduce(&sorted, &odd_sorted, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
        }
        else
        {
            MPI_Allreduce(&sorted, &even_sorted, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
        }
        if (odd_sorted + even_sorted == size)
            break;
    }
    ```

* 選擇 MPI_Sendrecv 交換數據
  
  因為可以同時完成 send 與 recv 的動作，不像 MPI_Send + MPI_Recv 需要彼此互相等待，容易產生 deadlock。另外，我也嘗試過使用 MPI_Isend + MPI_Irecv 的 non-blocking 組合，但發現仍然是 MPI_Sendrecv 表現更佳，故最後選用它。

* 本地陣列的 sorting 方式
  
  原本打算自己手刻 merge sort，因為 merge sort 在 worst case 的 time complexity 也有 O(nlogn)。但後來發現直接使用 `<boost>` 針對浮點數的 `boost::sort::spreadsort::float_sort`速度會更快。

* odd-even phase sorting 方式
  
  把左邊 process 的陣列與右邊 process 的陣列先合併後再用`boost::sort::spreadsort::sort`，會比現在的方法多出copy 兩個 array 的時間，經實測是現在的方法較有效率，故採用。

* odd-even phase sorting 概念

  一開始想到的是把 input 的 n 個數字，每個都當成一個元素來進行。如此不僅需要執行 n 次的 for loop ( 在 n 極大時執行時間會很可觀 )，還因為多了一堆 MPI_Sendrecv 的 communication time ，效率比 sequential 直接做來的差。

  後來改成把每個 process 視為一個元素，大家持有 sorting 好的本地陣列進行交換，確實少跑了很多次 for loop，也減少了大量的 communication time，至少再也沒有整排 TLE 的情況出現。

* 減少重複的動作

  在迴圈中會用到的變數及陣列等，都事先宣告和分配記憶體空間。另外，像是每次迴圈都要檢查邊界( size - 1)，也可以用 edge 變數替代，省去一些運算時間。

* 選擇 MPI_Allreduce
  
  嘗試過先用 MPI_Reduce 把所有訊息匯集到 rank 0，最後再用 MPI_Bcast 將結果廣播給其他 rank。但經實測發現直接使用 MPI_Allreduce 的 communication 開銷較小，故採用。

* 使用 bitwise operations 替代 arithmetic operations
  
  bitwise operations(& | ^)會直接操作二进制位，硬體處理速度較快。因此在檢查當前 phase 是 odd 還是 even 時，比起更直覺的 ```if ( phase % 2 == 0 )```這種 arithmetic operations( % * / )，改成使用 bitwise operations 搭配條件判斷。

* function 的定義位置

  經實測，function 直接在 main() 前定義，會比先宣告 function 然後在 main() 後定義，省上幾秒的時間，故採用。

## B. Experiment & Analysis

### i. Methodology

#### (a). System Spec

使用課堂提供的 server。

#### (b). Performance Metrics

| time | measurement |
| :--------------: | :-----------------------------------------------------------------: |
| computing time | 每個 process 合併自己與隔壁 process 的本地陣列並 sort 的時間 |
| communication time | MPI_Sendrecv + MPI_Allreduce 的 total time  |
| io time | MPI_File_open + MPI_File_close + MPI_File_read_at + MPI_File_write_at 的 total time | 
| preprocessing time | 每個 process 預先分配記憶體，及讀取資料後做本地陣列排序的時間 |

### ii. Plots

* Experimental Method

  使用 testcase 提供的 40.in 作為dataset，設定是根據 40.txt 中的內容。

* Time profile

  ![1 node](https://github.com/109062227/Parallel-Programming/blob/main/hw1/1%20node.png?raw=true)

  ![3 node](https://github.com/109062227/Parallel-Programming/blob/main/hw1/3%20node.png?raw=true)

  <!-- ![8 process / node](https://github.com/109062227/Parallel-Programming/blob/main/hw1/8%20process_per_node.png?raw=true) -->

  * Preprocessing time
  
    只有一個 process 時，會成為 bottle neck，因為對本地陣列做排序完全是 sequential 執行，並未 parallel。隨著 process 數量漸增，preprocessing time 下降不少，畢竟有更多的 process 可以分擔 local sort 以及 allocate memory 等工作
  ，實現平行化。

  * IO time
  
    比較 1 node 與 3 nodes的圖表，後者所花的 IO time 雖然稍微小於前者，但随着 process 數量增加，整體 IO time 卻沒有明顯的上升或是下降，故 IO time 也可能成為 bottle neck。推測是因為，若每個 process 都需要讀取或是寫入資料，process 越多，可能只會引入更多的 IO request。

  * Communication time
  
    隨著 process 數量增加，communication time 似乎不減反增。也許是因為，雖然每個 process 持有的 data 更少，彼此之間卻需要經過更多輪的溝通 ( 包含 MPI_Allreduce 與 MPI_Sendrecv 交換 data)。觀察 1 node 與 3 nodes 的圖表，後者多出的 node communication time 也沒有讓整體的 communication time 有顯著增長，故影響的主因大概還是多個 process 之間需要頻繁交換 data 。這會造成隨著 process 數量變多，communication time 也變成 bottle neck。

  * Coputation time
  
    並沒有隨著 process 增多而有明顯的上升或下降。推測也類似communication time：雖然每個 process 持有的 data 變少、交換後需要 merge & sort 的陣列變小，但整體的排序過程卻因為增加的交換輪次而變長。如此一來，process 數量變多並沒有帶來明顯的加速，反而是額外的交換輪次造成整體時間變動不大。

  綜上所述，主要的 bottle neck 應該還是出在 communication time 與 IO time。

* Speedup factor

  ![1 node scale factor](https://github.com/109062227/Parallel-Programming/blob/main/hw1/scale_1_node.png?raw=true)

  ![3 nodes scale factor](https://github.com/109062227/Parallel-Programming/blob/main/hw1/scale_3_node.png?raw=true)
  
  整體的 scaling 效果並不好，不管是 1 node 還是 3 node，大概都在 process 達到 5 ~ 8 個以後，speedup factor 就沒有上升趨勢。可能原因就是剛才提到的 communication time 與 IO time 的 bottle neck： process 數量增多意味著 data 被分成更多等分，需要大量的同步步驟及頻繁交換數據。改善的方法如下，

  * 指定特地幾個 process 負責 data 的讀寫就好 ( 減少 IO time )，其他 process 處理剩餘的並行化任務，像是計算與排序等。但可能會多出額外將 data 分送給其他 process 的時間，要注意是否會比所有 process 一起讀寫來的有效率。
  
  * communication time 的部分，non-blocking 也是可以嘗試的方向。但是要注意的實作細節可能更多，需要設定一些條件才能讓 communication 與 computation 適度重疊。

## C. Experiences / Conclusion

雖然 lab1 就有稍微接觸了一點，但這次作業才讓我真正更了解 MPI 的操作。一開始很不適應平行化的想法，很難從以前 sequential 的模式轉換過來，所以花了很多時間在琢磨分配任務給 process 以及它們之間的溝通上。另外，在優化的部分，我嘗試了很多 c++ 程式碼的優化，但最後觀察 time profile ，都只有讓 computation time 稍微減少，也許如何處理 communication time 與 IO time 這兩個 bottle neck 才是真正影響 performance 的關鍵。最後，謝謝教授以及助教，你們辛苦了！
